--- a/include/linux/netfilter.h	2011-03-13 05:00:00.000000000 +0500
+++ b/include/linux/netfilter.h	2011-03-14 17:49:47.333163002 +0500
@@ -21,7 +21,12 @@
 #define NF_STOLEN 2
 #define NF_QUEUE 3
 #define NF_REPEAT 4
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+#define NF_FAST_NAT 5
+#define NF_STOP 6
+#else
 #define NF_STOP 5
+#endif
 #define NF_MAX_VERDICT NF_STOP
 
 /* we overload the higher bits for encoding auxiliary data such as the queue
--- a/include/linux/sysctl.h	2008-02-26 04:59:40.000000000 +0500
+++ b/include/linux/sysctl.h	2011-03-14 17:49:09.073163002 +0500
@@ -530,6 +530,9 @@ enum
  	NET_IPV4_NF_CONNTRACK_SCTP_TIMEOUT_SHUTDOWN_ACK_SENT=26,
 	NET_IPV4_NF_CONNTRACK_COUNT=27,
 	NET_IPV4_NF_CONNTRACK_CHECKSUM=28,
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	NET_IPV4_CONNTRACK_FASTNAT=29,
+#endif
 };
  
 /* /proc/sys/net/ipv6 */
--- a/include/net/netfilter/nf_nat.h	2008-02-26 04:59:40.000000000 +0500
+++ b/include/net/netfilter/nf_nat.h	2011-03-14 19:07:25.203163002 +0500
@@ -56,6 +56,9 @@ struct nf_nat_multi_range_compat
 struct nf_nat_info
 {
 	struct list_head bysource;
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	u_int32_t nat_type;
+#endif
 	struct nf_nat_seq seq[IP_CT_DIR_MAX];
 };
 
--- a/net/ipv4/netfilter/bcm_nat.c	1970-01-01 05:00:00.000000000 +0500
+++ b/net/ipv4/netfilter/bcm_nat.c	2011-03-14 20:43:59.733163002 +0500
@@ -0,0 +1,206 @@
+/*
+ * Packet matching code.
+ *
+ * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling
+ * Copyright (C) 2009-2002 Netfilter core team <coreteam@netfilter.org>
+ *
+ * 19 Jan 2002 Harald Welte <laforge@gnumonks.org>
+ * 	- increase module usage count as soon as we have rules inside
+ * 	  a table
+ */
+#include <linux/config.h>
+#include <linux/cache.h>
+#include <linux/skbuff.h>
+#include <linux/kmod.h>
+#include <linux/vmalloc.h>
+#include <linux/netdevice.h>
+#include <linux/module.h>
+#include <linux/ip.h>
+#include <net/route.h>
+#include <net/ip.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#include <net/netfilter/nf_nat_core.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <linux/netfilter/nf_conntrack_common.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+
+#define DEBUGP(format, args...)
+
+typedef int (*bcmNatHitHook)(struct sk_buff *skb);
+typedef int (*bcmNatBindHook)(struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo,
+	struct sk_buff *skb,
+	struct nf_conntrack_l3proto *l3proto,
+	struct nf_conntrack_l4proto *l4proto);
+
+extern bcmNatHitHook bcm_nat_hit_hook;
+extern bcmNatBindHook bcm_nat_bind_hook;
+
+static inline int
+bcm_nat_hit_hook_func(bcmNatHitHook hook_func) {
+	bcm_nat_hit_hook = hook_func;
+	return 1;
+};
+
+static inline int
+bcm_nat_bind_hook_func(bcmNatBindHook hook_func) {
+	bcm_nat_bind_hook = hook_func;
+	return 1;
+};
+
+extern
+#ifndef MODULE
+inline
+#endif
+int bcm_manip_pkt(u_int16_t proto,
+	struct sk_buff *skb,
+	unsigned int iphdroff,
+	const struct nf_conntrack_tuple *target,
+	enum nf_nat_manip_type maniptype);
+
+extern
+#ifndef MODULE
+inline
+#endif
+int bcm_nf_ct_invert_tuple(struct nf_conntrack_tuple *inverse,
+	const struct nf_conntrack_tuple *orig,
+	const struct nf_conntrack_l3proto *l3proto,
+	const struct nf_conntrack_l4proto *l4proto);
+
+/* 
+ * Send packets to output.
+ */
+static inline int
+bcm_fast_path_output(struct sk_buff *skb)
+{
+	int ret = 0;
+	struct dst_entry *dst = skb->dst;
+	struct hh_cache *hh = dst->hh;
+
+	if (hh) {
+		unsigned seq;
+		int hh_len;
+
+		do {
+			int hh_alen;
+			seq = read_seqbegin(&hh->hh_lock);
+			hh_len = hh->hh_len;
+			hh_alen = HH_DATA_ALIGN(hh_len);
+			memcpy(skb->data - hh_alen, hh->hh_data, hh_alen);
+		} while (read_seqretry(&hh->hh_lock, seq));
+
+		skb_push(skb, hh_len);
+		ret = hh->hh_output(skb); 
+		if (ret==1) 
+			return 0; /* Don't return 1 */
+	} else if (dst->neighbour) {
+		ret = dst->neighbour->output(skb);  
+		if (ret==1) 
+			return 0; /* Don't return 1 */
+	}
+	return ret;
+}
+
+static inline int
+ip_skb_dst_mtu(struct sk_buff *skb)
+{
+	struct inet_sock *inet = skb->sk ? inet_sk(skb->sk) : NULL;
+
+	return (inet && inet->pmtudisc == IP_PMTUDISC_PROBE) ?
+	       skb->dst->dev->mtu : dst_mtu(skb->dst);
+}
+
+static int
+bcm_fast_path(struct sk_buff *skb)
+{
+	if (skb->dst == NULL) {
+		struct iphdr *iph = ip_hdr(skb);
+		struct net_device *dev = skb->dev;
+
+		if (ip_route_input(skb, iph->daddr, iph->saddr, iph->tos, dev)) {
+			return NF_DROP;
+		}
+		/*  Change skb owner to output device */
+		skb->dev = skb->dst->dev;
+	}
+
+	if (skb->dst) {
+		if (skb->len > ip_skb_dst_mtu(skb) && !skb_is_gso(skb))
+			return ip_fragment(skb, bcm_fast_path_output);
+		else
+			return bcm_fast_path_output(skb);
+	}
+
+	kfree_skb(skb);
+	return -EINVAL;
+}
+
+static int
+bcm_do_bindings(struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo,
+	struct sk_buff *skb,
+	struct nf_conntrack_l3proto *l3proto,
+	struct nf_conntrack_l4proto *l4proto)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	unsigned int i;
+	static int hn[2] = {NF_IP_PRE_ROUTING, NF_IP_POST_ROUTING};
+	enum ip_conntrack_dir dir = CTINFO2DIR(ctinfo);
+
+	for (i = 0; i < 2; i++) {
+		enum nf_nat_manip_type mtype = HOOK2MANIP(hn[i]);
+		unsigned long statusbit;
+
+		if (mtype == IP_NAT_MANIP_SRC)
+			statusbit = IPS_SRC_NAT;
+		else
+			statusbit = IPS_DST_NAT;
+
+		/* Invert if this is reply dir. */
+		if (dir == IP_CT_DIR_REPLY)
+			statusbit ^= IPS_NAT_MASK;
+
+		if (ct->status & statusbit) {
+			struct nf_conntrack_tuple target;
+
+			if (!skb_make_writable(skb, 0))
+					return NF_DROP;
+
+			if (skb->dst == NULL && mtype == IP_NAT_MANIP_SRC) {
+				struct net_device *dev = skb->dev;
+				if (ip_route_input(skb, iph->daddr, iph->saddr, iph->tos, dev))
+					return NF_DROP;
+				/* Change skb owner */
+				skb->dev = skb->dst->dev;
+			}
+
+			/* We are aiming to look like inverse of other direction. */
+			bcm_nf_ct_invert_tuple(&target, &ct->tuplehash[!dir].tuple, l3proto, l4proto);
+
+			if (!bcm_manip_pkt(target.dst.protonum, skb, 0, &target, mtype))
+				return NF_DROP;
+		}
+	}
+
+	return NF_FAST_NAT;
+}
+
+static int __init bcm_nat_init(void)
+{
+	bcm_nat_hit_hook_func (bcm_fast_path);
+	bcm_nat_bind_hook_func (bcm_do_bindings);
+	printk("BCM fast NAT: INIT\n");
+	return 0;
+}
+
+static void __exit bcm_nat_fini(void)
+{
+	bcm_nat_hit_hook_func (NULL);
+	bcm_nat_bind_hook_func (NULL);
+}
+
+module_init(bcm_nat_init);
+module_exit(bcm_nat_fini);
+MODULE_LICENSE("Proprietary");
--- a/net/ipv4/netfilter/Kconfig	2010-05-17 21:31:42.000000000 +0600
+++ b/net/ipv4/netfilter/Kconfig	2011-03-14 17:43:42.653163002 +0500
@@ -174,6 +174,14 @@ config NF_NAT_NEEDED
 	depends on NF_NAT
 	default y
 
+config BCM_NAT
+	tristate "Broadcom fast NAT support"
+	depends on NF_CONNTRACK && NF_NAT
+	default y
+	help
+	  This helps packets pass through netfilter faster when a packet
+	  is an established or reply traffic.
+
 config IP_NF_TARGET_MASQUERADE
 	tristate "MASQUERADE target support"
 	depends on NF_NAT
--- a/net/ipv4/netfilter/Makefile	2010-05-17 21:28:19.000000000 +0600
+++ b/net/ipv4/netfilter/Makefile	2011-03-14 17:58:38.553163002 +0500
@@ -18,6 +18,9 @@ obj-$(CONFIG_NF_CONNTRACK_IPV4) += nf_co
 
 obj-$(CONFIG_NF_NAT) += nf_nat.o
 
+# Broadcom NAT
+obj-$(CONFIG_BCM_NAT) += bcm_nat.o
+
 # NAT helpers (nf_conntrack)
 obj-$(CONFIG_NF_NAT_AMANDA) += nf_nat_amanda.o
 obj-$(CONFIG_NF_NAT_FTP) += nf_nat_ftp.o
--- a/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2011-03-14 20:42:58.603163002 +0500
@@ -30,6 +30,11 @@
 #define DEBUGP(format, args...)
 #endif
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+int ipv4_conntrack_fastnat = 1;
+EXPORT_SYMBOL_GPL(ipv4_conntrack_fastnat);
+#endif
+
 static int ipv4_pkt_to_tuple(const struct sk_buff *skb, unsigned int nhoff,
 			     struct nf_conntrack_tuple *tuple)
 {
@@ -63,7 +68,10 @@ static int ipv4_print_tuple(struct seq_f
 }
 
 /* Returns new sk_buff, or NULL */
-static int nf_ct_ipv4_gather_frags(struct sk_buff *skb, u_int32_t user)
+#if !defined(CONFIG_BCM_NAT) && !defined(CONFIG_BCM_NAT_MODULE)
+static
+#endif
+int nf_ct_ipv4_gather_frags(struct sk_buff *skb, u_int32_t user)
 {
 	int err;
 
@@ -302,6 +310,16 @@ static ctl_table ip_ct_sysctl_table[] = 
 		.extra1		= &log_invalid_proto_min,
 		.extra2		= &log_invalid_proto_max,
 	},
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	{
+		.ctl_name	= NET_IPV4_CONNTRACK_FASTNAT,
+		.procname	= "ip_conntrack_fastnat",
+		.data		= &ipv4_conntrack_fastnat,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec,
+	},
+#endif
 	{
 		.ctl_name	= 0
 	}
--- a/net/ipv4/netfilter/nf_nat_core.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/ipv4/netfilter/nf_nat_core.c	2011-03-14 20:42:43.803163002 +0500
@@ -392,6 +392,23 @@ manip_pkt(u_int16_t proto,
 	return 1;
 }
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+#ifndef CONFIG_BCM_NAT_MODULE
+inline
+#endif
+int bcm_manip_pkt(u_int16_t proto,
+	struct sk_buff *skb,
+	unsigned int iphdroff,
+	const struct nf_conntrack_tuple *target,
+	enum nf_nat_manip_type maniptype)
+{
+	return manip_pkt(proto, skb, iphdroff, target, maniptype);
+}
+#ifdef CONFIG_BCM_NAT_MODULE
+EXPORT_SYMBOL(bcm_manip_pkt);
+#endif
+#endif
+
 /* Do packet manipulations according to nf_nat_setup_info. */
 unsigned int nf_nat_packet(struct nf_conn *ct,
 			   enum ip_conntrack_info ctinfo,
--- a/net/netfilter/core.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/netfilter/core.c	2011-03-14 17:48:17.213163002 +0500
@@ -23,6 +23,11 @@
 
 #include "nf_internals.h"
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+typedef int (*bcmNatHitHook)(struct sk_buff *skb);
+extern bcmNatHitHook bcm_nat_hit_hook;
+#endif
+
 static DEFINE_MUTEX(afinfo_mutex);
 
 struct nf_afinfo *nf_afinfo[NPROTO] __read_mostly;
@@ -126,6 +131,13 @@ unsigned int nf_iterate(struct list_head
 {
 	unsigned int verdict;
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	if (!skb) {
+		NFDEBUG("nf_hook_slow, skb is empty return NF_STOP\n");
+		return NF_STOP;
+	}
+#endif
+
 	/*
 	 * The caller must not block between calls to this
 	 * function because of risk of continuing from deleted element.
@@ -133,6 +145,13 @@ unsigned int nf_iterate(struct list_head
 	list_for_each_continue_rcu(*i, head) {
 		struct nf_hook_ops *elem = (struct nf_hook_ops *)*i;
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+		if (!elem->hook) {
+			NFDEBUG("nf_hook_slow: elem is empty return NF_DROP\n");
+			return NF_DROP;
+		}
+#endif
+
 		if (hook_thresh > elem->priority)
 			continue;
 
@@ -140,6 +159,12 @@ unsigned int nf_iterate(struct list_head
 		   reference here, since function can't sleep. --RR */
 repeat:
 		verdict = elem->hook(hook, skb, indev, outdev, okfn);
+
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+		if (verdict == NF_FAST_NAT)
+			return NF_FAST_NAT;
+#endif
+
 		if (verdict != NF_ACCEPT) {
 #ifdef CONFIG_NETFILTER_DEBUG
 			if (unlikely((verdict & NF_VERDICT_MASK)
@@ -189,6 +214,17 @@ next_hook:
 			      verdict >> NF_VERDICT_BITS))
 			goto next_hook;
 	}
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	else if (verdict == NF_FAST_NAT) {
+		if (bcm_nat_hit_hook) {
+			ret = bcm_nat_hit_hook(skb);
+		}
+		else {
+			kfree_skb(skb);
+			ret = -EPERM;
+		}
+	}
+#endif
 unlock:
 	rcu_read_unlock();
 	return ret;
--- a/net/netfilter/nf_conntrack_core.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/netfilter/nf_conntrack_core.c	2011-03-19 21:53:05.993163002 +0500
@@ -30,6 +30,10 @@
 #include <linux/socket.h>
 #include <linux/mm.h>
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+#include <net/ip.h>
+#endif
+
 #include <net/netfilter/nf_conntrack.h>
 #include <net/netfilter/nf_conntrack_l3proto.h>
 #include <net/netfilter/nf_conntrack_l4proto.h>
@@ -76,6 +80,25 @@ static unsigned int nf_conntrack_next_id
 DEFINE_PER_CPU(struct ip_conntrack_stat, nf_conntrack_stat);
 EXPORT_PER_CPU_SYMBOL(nf_conntrack_stat);
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+#define	BCM_FASTNAT_DENY 1
+extern int ipv4_conntrack_fastnat;
+
+typedef int (*bcmNatHitHook)(struct sk_buff *skb);
+typedef int (*bcmNatBindHook)(struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo,
+	struct sk_buff *skb,
+	struct nf_conntrack_l3proto *l3proto,
+	struct nf_conntrack_l4proto *l4proto);
+
+bcmNatHitHook bcm_nat_hit_hook = NULL;
+bcmNatBindHook bcm_nat_bind_hook = NULL;
+#ifdef CONFIG_BCM_NAT_MODULE
+EXPORT_SYMBOL(bcm_nat_hit_hook);
+EXPORT_SYMBOL(bcm_nat_bind_hook);
+#endif
+#endif
+
 /*
  * This scheme offers various size of "struct nf_conn" dependent on
  * features(helper, nat, ...)
@@ -287,6 +310,22 @@ nf_ct_invert_tuple(struct nf_conntrack_t
 }
 EXPORT_SYMBOL_GPL(nf_ct_invert_tuple);
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+#ifndef CONFIG_BCM_NAT_MODULE
+inline
+#endif
+int bcm_nf_ct_invert_tuple(struct nf_conntrack_tuple *inverse,
+	const struct nf_conntrack_tuple *orig,
+	const struct nf_conntrack_l3proto *l3proto,
+	const struct nf_conntrack_l4proto *l4proto)
+{
+	return nf_ct_invert_tuple(inverse, orig, l3proto,l4proto);
+}
+#ifdef CONFIG_BCM_NAT_MODULE
+EXPORT_SYMBOL(bcm_nf_ct_invert_tuple);
+#endif
+#endif
+
 static void
 clean_from_lists(struct nf_conn *ct)
 {
@@ -837,6 +876,10 @@ resolve_normal_ct(struct sk_buff *skb,
 	return ct;
 }
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+extern int nf_ct_ipv4_gather_frags(struct sk_buff *skb, u_int32_t user);
+#endif
+
 unsigned int
 nf_conntrack_in(int pf, unsigned int hooknum, struct sk_buff *skb)
 {
@@ -848,6 +891,9 @@ nf_conntrack_in(int pf, unsigned int hoo
 	u_int8_t protonum;
 	int set_reply = 0;
 	int ret;
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	struct nf_conn_nat *nat = NULL;
+#endif
 
 	/* Previously seen (loopback or untracked)?  Ignore. */
 	if (skb->nfct) {
@@ -863,6 +909,19 @@ nf_conntrack_in(int pf, unsigned int hoo
 		return -ret;
 	}
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	if (pf == PF_INET && ipv4_conntrack_fastnat) {
+		/* Gather fragments. */
+		if (ip_hdr(skb)->frag_off & htons(IP_MF | IP_OFFSET)) {
+			if (nf_ct_ipv4_gather_frags(skb,
+						hooknum == NF_IP_PRE_ROUTING ?
+						IP_DEFRAG_CONNTRACK_IN :
+						IP_DEFRAG_CONNTRACK_OUT))
+				return NF_STOLEN;
+		}
+	}
+#endif
+
 	l4proto = __nf_ct_l4proto_find((u_int16_t)pf, protonum);
 
 	/* It may be an special packet, error, unclean...
@@ -902,8 +961,39 @@ nf_conntrack_in(int pf, unsigned int hoo
 		return -ret;
 	}
 
-	if (set_reply && !test_and_set_bit(IPS_SEEN_REPLY_BIT, &ct->status))
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	if (pf == PF_INET)
+		nat = nfct_nat(ct);
+
+	if (nat && hooknum == NF_IP_PRE_ROUTING &&
+	    ipv4_conntrack_fastnat && bcm_nat_bind_hook) {
+		struct nf_conn_help *help = nfct_help(ct);
+
+		if (!(nat->info.nat_type & BCM_FASTNAT_DENY) &&
+		    !help->helper &&
+		    (ctinfo == IP_CT_ESTABLISHED || ctinfo == IP_CT_IS_REPLY) &&
+		    (protonum == IPPROTO_TCP || protonum == IPPROTO_UDP)) {
+			struct nf_conntrack_tuple *t1, *t2;
+
+			t1 = &ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple;
+			t2 = &ct->tuplehash[IP_CT_DIR_REPLY].tuple;
+			if (!(t1->dst.u3.ip == t2->src.u3.ip &&
+				t1->src.u3.ip == t2->dst.u3.ip &&
+				t1->dst.u.all == t2->src.u.all &&
+				t1->src.u.all == t2->dst.u.all)) {
+				ret = bcm_nat_bind_hook(ct, ctinfo, skb, l3proto, l4proto);
+			}
+		}
+	}
+#endif
+
+	if (set_reply && !test_and_set_bit(IPS_SEEN_REPLY_BIT, &ct->status)) {
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+		if (nat && hooknum == NF_IP_LOCAL_OUT)
+			nat->info.nat_type |= BCM_FASTNAT_DENY;
+#endif
 		nf_conntrack_event_cache(IPCT_STATUS, skb);
+	}
 
 	return ret;
 }
--- a/net/netfilter/nf_conntrack_proto_tcp.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/netfilter/nf_conntrack_proto_tcp.c	2011-03-14 17:46:34.153163002 +0500
@@ -33,6 +33,10 @@
 #define DEBUGP(format, args...)
 #endif
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+extern int ipv4_conntrack_fastnat;
+#endif
+
 /* Protects conntrack->proto.tcp */
 static DEFINE_RWLOCK(tcp_lock);
 
@@ -759,6 +763,11 @@ static int tcp_error(struct sk_buff *skb
 	unsigned int tcplen = skb->len - dataoff;
 	u_int8_t tcpflags;
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	if (ipv4_conntrack_fastnat)
+		return NF_ACCEPT;
+#endif
+
 	/* Smaller that minimal TCP header? */
 	th = skb_header_pointer(skb, dataoff, sizeof(_tcph), &_tcph);
 	if (th == NULL) {
--- a/net/netfilter/nf_conntrack_proto_udp.c	2011-03-13 05:00:00.000000000 +0500
+++ b/net/netfilter/nf_conntrack_proto_udp.c	2011-03-14 17:45:59.873163002 +0500
@@ -23,6 +23,10 @@
 #include <net/netfilter/nf_conntrack_l4proto.h>
 #include <net/netfilter/nf_conntrack_ecache.h>
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+extern int ipv4_conntrack_fastnat;
+#endif
+
 static unsigned int nf_ct_udp_timeout __read_mostly = 30*HZ;
 static unsigned int nf_ct_udp_timeout_stream __read_mostly = 180*HZ;
 
@@ -97,6 +101,11 @@ static int udp_error(struct sk_buff *skb
 	unsigned int udplen = skb->len - dataoff;
 	struct udphdr _hdr, *hdr;
 
+#if defined(CONFIG_BCM_NAT) || defined(CONFIG_BCM_NAT_MODULE)
+	if (ipv4_conntrack_fastnat)
+		return NF_ACCEPT;
+#endif
+
 	/* Header is too small? */
 	hdr = skb_header_pointer(skb, dataoff, sizeof(_hdr), &_hdr);
 	if (hdr == NULL) {
